{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import urllib\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyasawkar/anaconda3/envs/paperClassifier/lib/python3.7/site-packages/bs4/__init__.py:335: UserWarning: \"https://arxiv.org/abs/1808.10393\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "topCategoryArray = [\n",
    "\"Computer Vision\",\n",
    "\"Natural Language Processing\",\n",
    "\"Methodology\",\n",
    "\"Representation Learning\",\n",
    "\"SEMANTIC SEGMENTATION\",\n",
    "\"MACHINE TRANSLATION\",\n",
    "\"Graphs\",\n",
    "\"WORD EMBEDDINGS\",\n",
    "\"Time Series\",\n",
    "\"Miscellaneous\",\n",
    "\"QUESTION ANSWERING\",\n",
    "\"Speech\",\n",
    "\"IMAGE CLASSIFICATION\",\n",
    "\"Video\",\n",
    "\"OBJECT DETECTION\",\n",
    "\"SENTIMENT ANALYSIS\",\n",
    "\"Facial Recognition and Modelling\",\n",
    "\"Medical\",\n",
    "\"TIME SERIES\"\n",
    "]\n",
    "\n",
    "json_data = []\n",
    "\n",
    "firstRowData = []\n",
    "firstRowData.append('Title')\n",
    "for category in topCategoryArray:\n",
    "    firstRowData.append(category)\n",
    "    \n",
    "    \n",
    "json_data.append(firstRowData)\n",
    "with open('JsonToCsv1.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            \n",
    "#             line_count += 1\n",
    "#             if(line_count>3):\n",
    "#                 break\n",
    "            rowTitle = row[0];\n",
    "            githubUrl = row[2];\n",
    "            url = ('https://paperswithcode.com/search?q='+row[0]).replace(\" \",\"%20\")\n",
    "    #         print(url)\n",
    "            response = requests.get(url)\n",
    "            html = response.content\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            firstCard = soup.find('div',attrs={'class': 'row infinite-item item'})\n",
    "            spans = firstCard.findAll('span', attrs={'class': 'badge badge-primary'})\n",
    "            categories = []\n",
    "            heirarchyCategories = []\n",
    "            for span in spans:\n",
    "                categories.append(span.text)\n",
    "#             print(categories)\n",
    "            for category in categories:\n",
    "                categortUrl = 'https://paperswithcode.com/task/'+str(category).lower().replace(\" \",\"-\")\n",
    "                categortUrlResponse = requests.get(categortUrl)\n",
    "                categortUrlHtml = categortUrlResponse.content\n",
    "                categortUrlSoup = BeautifulSoup(categortUrlHtml, \"html.parser\")\n",
    "                categoryDiv = categortUrlSoup.find('div',attrs={'class': 'general-breadcrumb'})\n",
    "                \n",
    "                for span in categoryDiv.findAll('a'):\n",
    "                    if(span.text!='Browse'):\n",
    "                        heirarchyCategories.append(span.text)\n",
    "#                 print(heirarchyCategories)\n",
    "            \n",
    "#             get paper url\n",
    "            itemContent = firstCard.find('div',attrs={'class': 'col-lg-9 item-content'})\n",
    "            anchorTag = itemContent.find('h1').find('a')['href']\n",
    "#             print(anchorTag)\n",
    "            paperUrl = 'https://paperswithcode.com'+ anchorTag\n",
    "            \n",
    "#             get paper abstract\n",
    "            response = requests.get(paperUrl)\n",
    "            html = response.content\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            paperAbstract = soup.find('div',attrs={'class': 'paper-abstract'}).find('p').text\n",
    "#           print(paperAbstract)\n",
    "#           get github readme\n",
    "            \n",
    "            githubUrl = githubUrl+\"/blob/master/README.md\"\n",
    "#             print(githubUrl)\n",
    "            response = requests.get(githubUrl)\n",
    "            html = response.content\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            rawUrl = soup.find('a',attrs={'id': 'raw-url'})['href']\n",
    "#             print(rawUrl)\n",
    "            response = requests.get('https://github.com'+rawUrl)\n",
    "            html = response.content\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            \n",
    "#             print(soup)\n",
    "#             githubReadme = soup.find('pre').text\n",
    "#             print(githubReadme)\n",
    "    \n",
    "            textForClassifier = str(paperAbstract) + str(soup)\n",
    "#             print(textForClassifier)\n",
    "            textForClassifier = textForClassifier.replace(\",\",\"\").replace(\"\\n\",\"\").strip()\n",
    "            rowData = []\n",
    "            rowData.append(textForClassifier)\n",
    "            for category in topCategoryArray:\n",
    "                if category in heirarchyCategories:\n",
    "                    rowData.append(\"1\")\n",
    "                else:\n",
    "                    rowData.append(\"0\")\n",
    "                \n",
    "            json_data.append(rowData);\n",
    "#             print(rowData)\n",
    "                            \n",
    "        except Exception as e:\n",
    "#             print(e)\n",
    "            continue;\n",
    "        \n",
    "with open('/Users/shreyasawkar/PycharmProjects/CSCI-548-Project/venv/Task1-DataExtraction/ProcessedData.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(json_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = []\n",
    "with open('ProcessedData.csv',encoding = \"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        line_count += 1\n",
    "        if(line_count==1):\n",
    "            continue\n",
    "        try:\n",
    "            rowData = [];\n",
    "            if(row[0]==null or row[0]==\" \" or row[1]==\" \"):\n",
    "                continue;\n",
    "            rowData.append(row[0])\n",
    "            i = 1\n",
    "            while(i<20):\n",
    "#                 print(row[i])\n",
    "                if(row[i]=='0'):\n",
    "                    rowData.append(int(0))\n",
    "                else:\n",
    "                    rowData.append(int(1))\n",
    "                i += 1    \n",
    "            json_data.append(rowData)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "            \n",
    "with open('/Users/shreyasawkar/PycharmProjects/CSCI-548-Project/venv/Task1-DataExtraction/FinalProcessedData.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(json_data) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperClassifier",
   "language": "python",
   "name": "paperclassifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
